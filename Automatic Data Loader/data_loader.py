# -*- coding: utf-8 -*-
"""Data Loader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-hbaw349dGDBo6z-S71O-U1D_Ktmev26

# Main Data Loader Class
"""

# -*- coding: utf-8 -*-
"""Notes
1. creditcard.csv file has to be uploaded to the same folder to be able to use it!
2. creditcard.csv is available at https://www.kaggle.com/mlg-ulb/creditcardfraud
3. Dataset names: cifar10 - cifar100 - creditcard - omniglot

"""
from keras.datasets import cifar10, cifar100
from sklearn.model_selection import train_test_split
import numpy as np
import keras 
import pandas as pd

import os
import imageio
import numpy as np
import shutil
import zipfile
import wget


class data_loader:

  path = os.path.join(os.path.dirname(os.path.realpath('__file__')))
  os.chdir(path)

  def get_dataset(self, ds_name, normalize,ratio):

        print("Dataset:",ds_name)  
        if ds_name == 'cifar10':
          x_train, x_val, x_test, y_train, y_val, y_test = self.get_cifar10(ratio)
          normalize = True
        elif ds_name == 'cifar100':
          x_train, x_val, x_test, y_train, y_val, y_test = self.get_cifar100(ratio)
          normalize = True
        elif ds_name == 'creditcard':   
          x_train, x_val, x_test, y_train, y_val, y_test = self.get_creditcard(ratio)
        elif ds_name == 'omniglot':   
          x_train, x_val, x_test, y_train, y_val, y_test = self.get_omniglot(ratio)

        # Reshaping Targets/Classes
        num_classes = int(np.max(y_test)+1)
        y_train = keras.utils.to_categorical(y_train, num_classes)
        y_val = keras.utils.to_categorical(y_val, num_classes)
        y_test = keras.utils.to_categorical(y_test, num_classes)

        #Normalizing Features for cifar datasets
        if normalize:
            x_train, x_val, x_test = self.normalize_data(ds_name, x_train, x_val, x_test)

        return x_train, x_val, x_test, y_train, y_val, y_test

  def get_cifar10(self, ratio):
        (x_train, y_train), (x_test, y_test) = cifar10.load_data()
        X = np.concatenate((x_train, x_test), axis=0)
        y = np.concatenate((y_train, y_test), axis=0)

        return self.train_val_test_splitter(X, y, ratio, random_state=999)

  def get_cifar100(self, ratio):
        (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')
        X = np.concatenate((x_train, x_test), axis=0)
        y = np.concatenate((y_train, y_test), axis=0)

        return self.train_val_test_splitter(X, y, ratio, random_state=999)       

  def get_creditcard(self, ratio):
        data = pd.read_csv('creditcard.csv')
        X = data.loc[:, data.columns != 'Class'].values
        y = data.iloc[:,-1].values
        y = y.reshape((len(y), 1))

        return self.train_val_test_splitter(X, y, ratio,  random_state=999)

  def train_val_test_splitter(self, X, y, ratio, random_state=999):
        x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=ratio, random_state=999)
        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=ratio/(1-ratio), random_state=999)

        return x_train, x_val, x_test, y_train, y_val, y_test


  def normalize_data(self, ds_name, x_train, x_val, x_test):
        if ds_name == 'cifar10' or ds_name == 'cifar100':
              x_train = x_train/255
              x_val = x_val/255
              x_test = x_test/255
        return x_train, x_val, x_test

  #--- Omniglot ---
  def unzip(self):
    with zipfile.ZipFile('omniglot-master.zip', 'r') as zip_ref:
      zip_ref.extractall()
    with zipfile.ZipFile('omniglot-master/python/images_evaluation.zip', 'r') as zip_ref:
      zip_ref.extractall()
    with zipfile.ZipFile('omniglot-master/python/images_background.zip', 'r') as zip_ref:
      zip_ref.extractall()

  #Convert images to array    
  def parse_images(self, data):
    images = []
    for img in data:
      im = imageio.imread(img)
      images.append(im)
    return images

  #Cleans image files and zip after getting arrays
  def clean(self):
    os.remove('omniglot-master.zip')
    shutil.rmtree('omniglot-master')
    shutil.rmtree('images_evaluation')
    shutil.rmtree('images_background')

  def get_omniglot(self, ratio):

    # Download dataset from GitHub Repo
    url = 'https://github.com/brendenlake/omniglot/archive/master.zip'
    wget.download(url)
    #!wget https://github.com/brendenlake/omniglot/archive/master.zip
    # Unzip dataset
    self.unzip()  
    count = 0

    # Wrap all images
    alphabets, letters, labels = [], [], []   
    for file in os.listdir("images_background"):
        alphabets.append(os.path.join("images_background", file))
    for file in os.listdir("images_evaluation"):
        alphabets.append(os.path.join("images_evaluation", file))

    for alpha in alphabets:
      for file in os.listdir(alpha+'/'):

        path = os.path.join(alpha, file)

        for f in os.listdir(path):
          letters.append(path+'/'+f)
          labels.append(int(count))

        count += 1
    # Convert PNGs to arrays
    images = self.parse_images(letters)
    # Clean Base Dir from downloads
    self.clean()

    return  self.train_val_test_splitter(np.array(images), np.array(labels), ratio, random_state=999)

