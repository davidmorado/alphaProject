import pickle
import numpy as np
from keras.datasets import cifar10
from keras.utils import to_categorical
from CNN_VK import CNN_VK
from fit_evaluate import fit_evaluate
import sys  
import os
from sample import sample

# creates folders
folders = ['models', 'gridresults', 'tb_logs', 'errs', 'logs']
for f in folders:
    try:
        os.makedirs(f)
    except OSError:
        pass

# Data Loading and Preprocessing 
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
input_shape = x_train.shape[1:]
num_classes = np.max(y_test)+1
num_samples = x_train.shape[0]

x_train = x_train/255
x_test = x_test/255
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# number of target categories
num_categories = 3

x_train, y_train = sample(x_train, y_train, 1, num_categories)
num_classes = np.max(y_test)+1
num_samples = x_train.shape[0]
    
# Hyperparameters:
# number of target categories
num_categories = num_categories
# batch size to train SGD
batch_size = 64
# number of epochs to train the network for
epochs = 500
epochs = 100
    
# Hyperparameters:
# learning rate
print(sys.argv)
lr = float(sys.argv[1])
# bandwidth parameter for kernel regression
bandwidth = float(sys.argv[2])
# number of keys per class
n_keys_per_class = int(sys.argv[3])
# size of the embedding generated by CNN_VK
embedding_dim = int(sys.argv[4])
# Training percentage (change to check if code even runs)
p = float(sys.argv[5])

print("Percentage of training =", p)
idx = np.random.choice(num_samples, int(p*num_samples))
x_train_ = x_train[idx,]
y_train_ = y_train[idx,]

print("CNN+Keys...")
print("CNN with " + str(n_keys_per_class) + " keys per class.")
model = CNN_VK(
    num_categories,
    input_shape=input_shape, 
    layers=[32, 64, 512], 
    #num_categories=num_categories, 
    embedding_dim=embedding_dim, 
    n_keys_per_class=n_keys_per_class, 
    bandwidth=bandwidth)

modelpath = F'lr={lr}_bw={bandwidth}_kpc={n_keys_per_class}_es={embedding_dim}_tp={p}'

results = fit_evaluate(model, x_train_, y_train_, x_test, y_test, batch_size, epochs, lr, logstring=F'tb_logs/{modelpath}')

# causes OSError: Unable to create file (unable to lock file, errno = 37, error message = 'No locks available')
# model.save(F'models/' + modelpath)

filename = F"gridresults/{modelpath}.pkl"

with open(filename, 'wb') as f:
  pickle.dump(results, f)
