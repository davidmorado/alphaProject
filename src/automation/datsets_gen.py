# -*- coding: utf-8 -*-
"""datsets_gen.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aVnP61kZ1J5B0Z0wd6P7qPXwUO4goCUq
"""

from keras.datasets import cifar10, cifar100
from sklearn.model_selection import train_test_split
import numpy as np
import keras 
import pandas as pd

import os
import imageio
import numpy as np
import shutil
import zipfile

def get_dataset(ds_name, normalize=False):
  if ds_name == 'cifar10':
    (x_train, y_train), (x_test, y_test) = cifar10.load_data()
  elif ds_name == 'cifar100':
    (x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')
  elif ds_name == 'creditcard':   
    x_train, x_test, y_train, y_test = get_creditCard()
  
  # Reshaping Targets/Classes
  num_classes = np.max(y_test)+1
  num_samples = x_train.shape[0]
  y_train = keras.utils.to_categorical(y_train, num_classes)
  y_test = keras.utils.to_categorical(y_test, num_classes)
  
  #Normalizing Features
  if normalize:
    x_train, x_test = normalize_data(x_train, x_test)
    
  return x_train, y_train, x_test, y_test

def normalize_data(x_train, x_test):
  if ds_name == 'cifar10' or ds_name == 'cifar100':
        x_train = x_train/255
        x_test = x_test/255
  return x_train, x_test

def get_creditCard():
  data = pd.read_csv('creditcard.csv')
  X = data.loc[:, data.columns != 'Class'].values
  Y = data.iloc[:,-1].values
  Y = Y.reshape((len(Y), 1))
  
  x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)
  return x_train, x_test, y_train, y_test

x_train, y_train, x_test, y_test = get_dataset('creditcard')



x_train.shape, y_train.shape, x_test.shape, y_test.shape

import os
import imageio
import numpy as np
import shutil
import zipfile


def unzip():
  with zipfile.ZipFile('master.zip', 'r') as zip_ref:
    zip_ref.extractall()
  with zipfile.ZipFile('omniglot-master/python/images_evaluation.zip', 'r') as zip_ref:
    zip_ref.extractall()
    
def parse_images(data):
  images = []
  for img in data:
    im = imageio.imread(img)
    images.append(im)
  return images

def clean():
  shutil.rmtree('omniglot-master')
  os.remove('master.zip')
  
  

def get_omniglot():
  
  # Download dataset from GitHub Repo
  !wget https://github.com/brendenlake/omniglot/archive/master.zip
  # Unzip dataset
  unzip()
  
  count = 0
  # Wrap all images
  alphabets, letters, labels = [], [], []
  for file in os.listdir("images_evaluation"):
      alphabets.append(os.path.join("images_evaluation", file))

  for alpha in alphabets:
    for file in os.listdir(alpha+'/'):
      count+=1
      path = os.path.join(alpha, file)
      for f in os.listdir(path):
        letters.append(path+'/'+f)
        labels.append(file)
  
  # Convert PNGs to arrays
  images = parse_images(letters)
  # Clean Base Dir from downloads
  clean()

  return np.array(images), np.array(labels),count

imgs, lbs, count = get_omniglot()
imgs.shape, lbs.shape, count

imgs.shape, lbs.shape, count

lbs[0]
np.unique(lbs)
len(lbs[lbs == 'character55'])