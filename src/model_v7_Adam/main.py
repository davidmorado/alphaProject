import pickle
import numpy as np
from keras.datasets import cifar10
from keras.utils import to_categorical
from CNN_VK import CNN_VK
from fit_evaluate import fit_evaluate
import sys
import os

# creates folders
folders = ['models', 'gridresults', 'tb_logs', 'errs', 'logs']
for f in folders:
    try:
        os.makedirs(f)
    except OSError:
        pass

# Data Loading and Preprocessing
(x_train, y_train), (x_test, y_test) = cifar10.load_data()
input_shape = x_train.shape[1:]
num_classes = np.max(y_test)+1
num_samples = x_train.shape[0]

x_train = x_train/255
x_test = x_test/255
y_train = to_categorical(y_train, num_classes)
y_test = to_categorical(y_test, num_classes)

# Hyperparameters:
# number of target categories
num_categories = 10
# batch size to train SGD
batch_size = 64
# number of epochs to train the network for
epochs = 500

# Hyperparameters:
hp_dict = {
    'bandwidth': float(sys.argv[1]),
    'n_keys_per_class': int(sys.argv[2]),
    'embedding_dim': int(sys.argv[3]),
    'train_percentage': float(sys.argv[4]),
    'learning_rate': float(sys.argv[5])
}
# bandwidth parameter for kernel regression
bandwidth = hp_dict['bandwidth']
# number of keys per class
n_keys_per_class = hp_dict['n_keys_per_class']
# size of the embedding generated by CNN_VK
embedding_dim = hp_dict['embedding_dim']
# Training percentage (change to check if code even runs)
train_percentage = hp_dict['train_percentage']
# learning rate 
learning_rate = hp_dict['learning_rate']

print("Percentage of training =", train_percentage)
idx = np.random.choice(num_samples, int(train_percentage*num_samples))
x_train_ = x_train[idx,]
y_train_ = y_train[idx,]

model = CNN_VK(
    num_categories,
    input_shape=input_shape, 
    layers=[32, 64, 512], 
    embedding_dim=embedding_dim, 
    n_keys_per_class=n_keys_per_class, 
    bandwidth=bandwidth)

modelpath = F"Adam_lr={learning_rate}_bw={hp_dict['bandwidth']}_kpc={hp_dict['n_keys_per_class']}_es={hp_dict['embedding_dim']}_tp={hp_dict['train_percentage']}"

metrics_dict, memory = fit_evaluate(model, x_train_, y_train_, x_test, y_test, batch_size, epochs, lr=learning_rate, logstring=F'tb_logs/{modelpath}')

# causes OSError: Unable to create file (unable to lock file, errno = 37, error message = 'No locks available')
# model.save(F'models/' + modelpath)

out_results = (hp_dict, metrics_dict, memory)
filename = F"gridresults/{modelpath}.pkl"
with open(filename, 'wb') as f:
  pickle.dump(out_results, f)
