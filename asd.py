#!/usr/bin/env python
# coding: utf-8

# ## Name: Alperen Dedeoglu
# ## Mat. N.: 246106
# 
# ### Distributed Data Analytics - Exercise 5   

# In[121]:


import tensorflow as tf
import pandas as pd                      #library pandas
from matplotlib import pyplot as plt     #library matplot
import numpy as np
np.set_printoptions(threshold=7)
tf.set_random_seed(101) 
import os  


# ### 1. Linear Regression

# #### 1A: Univariate Linear Regression

#  - Toy Data is generated by tensors. 

# In[ ]:


half = tf.constant(0.5, shape=[1000, 1] ,dtype = 'float32')
x=tf.random.uniform([1000,1] ,dtype = 'float32')
two = tf.constant(2, shape=[1000, 1] ,dtype = 'float32')
L = tf.random_normal([1000,1] , mean=0.0, stddev=50, dtype=tf.dtypes.float32)

y = tf.add(tf.add(two,tf.multiply(half,x)),L)


#  - Train and test split for data with 90% to 10%.

# In[ ]:


def train_test_split(X,y,r):
    
    n=x.get_shape().as_list()[0]
    k=int(n*r)
    print(n)
    

    X_train, X_test= tf.split(X, [k,n-k], 0)
    y_train, y_test= tf.split(y, [k,n-k], 0)
    
    return X_train,X_test,y_train,y_test

r = 0.9
X_train,X_test,y_train,y_test = train_test_split(x,y,r)


# In[323]:


# Tensor parameters are created 
X = tf.placeholder("float") 
Y = tf.placeholder("float")

W = tf.Variable([0.0])
b = tf.Variable([0.0])


# In[324]:


# Prediction and loss functions are created 
y_pred = tf.add(tf.multiply(X, W), b) 
loss = tf.reduce_mean(tf.square(Y-y_pred))


#  - Tensor flow implementation for linear regression by showing loss change and fits for train and test data.

# In[67]:


optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00001)
minimize = optimizer.minimize(loss)
init = tf.global_variables_initializer()

with tf.Session() as sess:
    sess.run(init)
    
    X_train_arr=X_train.eval()
    y_train_arr=y_train.eval()
    
    X_test_arr=X_test.eval()
    y_test_arr=y_test.eval()
    
    Beginning_Loss = sess.run(loss, feed_dict = {X : X_train_arr, Y : y_train_arr})
    print("Loss at the Beginning =", Beginning_Loss)
    print("")
    for i in range(100):
        
        for (x, y) in zip(X_train_arr, y_train_arr): 

            sess.run(minimize, feed_dict = {X : x, Y : y})
        
        if (i + 1) % 10 == 0: 
            # Calculates loss at every 10th epoch
            Loss = sess.run(loss, feed_dict = {X : X_train_arr, Y : y_train_arr}) 
            print("Epoch", (i + 1), ": Loss =", Loss, 
                  ", Weigth =", sess.run(W)[0], ", Bias =", sess.run(b)[0]) 
 
    weight, bias = sess.run([W, b])
        
    predictions = weight * X_train_arr + bias
    print("Training Loss =", Loss)
    
    # Scatter Plot for the Train data 
    fig, ax = plt.subplots(figsize=(8, 5))
    plt.plot(X_train_arr, y_train_arr, 'bo', label ='Train Instances') 
    plt.plot(X_train_arr, predictions, 'r',label ='Fitted line') 
    plt.title('Linear Regression Result for Train Data') 
    plt.xlabel('X_train')
    plt.ylabel('y_train')
    plt.legend() 
    plt.show()
    
    test_predictions = weight * X_test_arr + bias
    Test_Loss = sess.run(loss, feed_dict = {X : X_test_arr, Y : y_test_arr}) 
    print("Testing Loss =", Test_Loss)
    
    # Scatter Plot for the Test data 
    fig, ax = plt.subplots(figsize=(8, 5))
    plt.plot(X_test_arr, y_test_arr, 'bo', label ='Test Instances') 
    plt.plot(X_test_arr, test_predictions, 'g',label ='Fitted line')    
    plt.title('Linear Regression Result for Test Data') 
    plt.xlabel('X_test')
    plt.ylabel('y_test')
    plt.legend() 
    plt.show()
    


# #### 1B: Multivariate Linear Regression

# In[122]:


path = os.path.join(os.path.dirname(os.path.realpath('__file__')))


# In[123]:


data = pd.read_csv("auto-mpg.data",header=None,delim_whitespace=True, 
                                               na_values = ['NA', '?'])


# In[124]:


data.head()


#  - NA values for auto-mpg dataset is checked below. There are 6 missing cells for 4th column. These cells are filled median values for these columns.

# In[125]:


print(data.info())


# In[126]:


#NA and Null check for Auto Data
print(data.shape)
print(data.dropna(how="any").shape)
print(data.isnull().values.any())


# In[127]:


data_filled=data.fillna(data.median())


# In[128]:


data_filled.head()


#   - No more NA values for the Auto-mpg data.

# In[129]:


#NA and Null check for Auto Data
print(data_filled.shape)
print(data_filled.dropna(how="any").shape)
print(data_filled.isnull().values.any())


#   - Categorical variables are converted to binary format with one_hot encoding.

# In[130]:


#One-hot encoding for categorical variables in bank data
data_onehot = pd.get_dummies(data_filled, sparse=True)
data_onehot.iloc[:,:12].head()


# In[131]:


print(data_onehot.info())


#   - Feature data is normalized and data format is converted to float32. Targets are assigned form first column of auto-mpg data.

# In[132]:


def normalize(X):
    return (X - X.min()) / (X.max() - X.min())

y_train = data_onehot.loc[:,0].values.reshape(-1,1)
X_train = normalize(data_onehot.iloc[:,1:].values)

y_train=y_train.astype('float32')
X_train=X_train.astype('float32')


# In[133]:


# Variables are created
X = tf.placeholder("float")
Y = tf.placeholder("float")

W = tf.Variable(tf.zeros([X_train.shape[1],1]),dtype=tf.float32)
b = tf.Variable([0.0])


#   - Prediction and error functions are created. (Mean Absolute Error, Mean Square Error and Root
# Mean Squared Error)

# In[134]:


y_pred = tf.add(tf.matmul(X,W), b)

mse = tf.reduce_mean(tf.square(Y-y_pred))
rmse = tf.sqrt(tf.reduce_mean(tf.square(tf.subtract(Y,y_pred))))
mae = tf.reduce_mean(tf.abs(tf.subtract(Y,y_pred)))


# #### 1. MSE

# In[136]:


N=50
lr = [0.00001,0.0001,0.001]

print("For MSE:")
final_loss=[]
for k in lr:
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=k)
    minimize_mse = optimizer.minimize(mse)
    init_mse = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init_mse)

        X_train_arr=X_train
        y_train_arr=y_train

        Losses = []
        Beginning_Loss = sess.run(mse, feed_dict = {X : X_train_arr,
                                                    Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        #print("MSE at the Beginning =", Beginning_Loss)
        #print("")
        for i in range(N):

            for (x, y) in zip(X_train_arr, y_train_arr): 

                sess.run(minimize_mse, feed_dict = {X : x.reshape(1,-1), Y : y})

                Loss = sess.run(mse, feed_dict = {X : X_train_arr, 
                                                  Y : y_train_arr})

            Losses.append(Loss)    

        weight, bias = sess.run([W, b])
        
        predictions = tf.add(tf.matmul(X_train,weight),b)
        
        fig, ax = plt.subplots(figsize=(8, 5))
        
        if k == 0.001:
            plt.plot(y_train,predictions.eval(), 'go',label ='Instances') 
        elif k == 0.0001:
            plt.plot(y_train,predictions.eval(), 'ro',label ='Instances')
        else:
            plt.plot(y_train,predictions.eval(), 'bo',label ='Instances') 
        plt.title('Comparison of Ground Truth and '+
                  'Predictions with \u03B1 = '+str(k)+' after 50 epochs') 
        plt.xlabel('Ground Truth Values')
        plt.ylabel('Predictions')
        plt.legend() 
        plt.show()
        
    final_loss.append(Losses) 
    
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='1e-05')
plt.plot(final_loss[1], 'r',label ='1e-04')
plt.plot(final_loss[2], 'g',label ='1e-03')
plt.title('MSE for Auto-Mpg Data for Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('MSE')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show() 


# #### 2. RMSE

# In[137]:


N=50
lr = [0.00001,0.0001,0.001]

print("For RMSE:")
final_loss=[]
for k in lr:
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=k)
    minimize_rmse = optimizer.minimize(rmse)
    init_rmse = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init_rmse)

        X_train_arr=X_train
        y_train_arr=y_train

        Losses = []
        Beginning_Loss = sess.run(rmse, feed_dict = {X : X_train_arr, 
                                                     Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        for i in range(N):

            for (x, y) in zip(X_train_arr, y_train_arr): 

                sess.run(minimize_rmse, feed_dict = {X : x.reshape(1,-1), Y : y})

                Loss = sess.run(rmse, feed_dict = {X : X_train_arr, 
                                                   Y : y_train_arr})

            Losses.append(Loss)    

        weight, bias = sess.run([W, b])
        
        predictions = tf.add(tf.matmul(X_train,weight),b)
        
        
        fig, ax = plt.subplots(figsize=(8, 5))
        if k == 0.001:
            plt.plot(y_train,predictions.eval(), 'go',label ='Instances') 
        elif k == 0.0001:
            plt.plot(y_train,predictions.eval(), 'ro',label ='Instances')
        else:
            plt.plot(y_train,predictions.eval(), 'bo',label ='Instances')
            
        plt.title('Comparison of Ground Truth and '+
                  'Predictions with \u03B1 = '+str(k)+' after 50 epochs') 
        plt.xlabel('Ground Truth Values')
        plt.ylabel('Predictions')
        plt.legend() 
        plt.show()
        
    final_loss.append(Losses) 
    
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='10e-5')
plt.plot(final_loss[1], 'r',label ='10e-4')
plt.plot(final_loss[2], 'g',label ='10e-3')
plt.title('RMSE for Auto-Mpg Data for Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('RMSE')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show() 


# #### 3. MAE

# In[138]:


N=50
lr = [0.00001,0.0001,0.001]

print("For MAE:")
final_loss=[]
for k in lr:
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=k)
    minimize_mae = optimizer.minimize(mae)
    init_mae = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init_mae)

        X_train_arr=X_train
        y_train_arr=y_train

        Losses = []
        Beginning_Loss = sess.run(mae, feed_dict = {X : X_train_arr, 
                                                    Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        for i in range(N):

            for (x, y) in zip(X_train_arr, y_train_arr): 

                sess.run(minimize_mae, feed_dict = {X : x.reshape(1,-1), Y : y})

                Loss = sess.run(mae, feed_dict = {X : X_train_arr, 
                                                  Y : y_train_arr})

            Losses.append(Loss)    

        weight, bias = sess.run([W, b])
        
        predictions = tf.add(tf.matmul(X_train,weight),b)
        
        fig, ax = plt.subplots(figsize=(8, 5)) 
        if k == 0.001:
            plt.plot(y_train,predictions.eval(), 'go',label ='Instances') 
        elif k == 0.0001:
            plt.plot(y_train,predictions.eval(), 'ro',label ='Instances')
        else:
            plt.plot(y_train,predictions.eval(), 'bo',label ='Instances') 
        plt.title('Comparison of Ground Truth and '+
                  'Predictions with \u03B1 = '+str(k)+' after 50 epochs') 
        plt.xlabel('Ground Truth Values')
        plt.ylabel('Predictions')
        plt.legend() 
        plt.show()
        
    final_loss.append(Losses) 
    
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='1e-05')
plt.plot(final_loss[1], 'r',label ='1e-04')
plt.plot(final_loss[2], 'g',label ='1e-03')
plt.title('MAE for Auto-Mpg Data for Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('MAE')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show() 


#   - For each 3 types of loss graphs (MSE-RMSE-MAE), loss decreases after training of epochs. When the learning rate increases the GD algorithm decreases loss more in aggressive way and it can be seen by loss graphs for 3 loss metrics. For each of them green lines with higher learning rate converges faster and the predictions based on lower loss is better which can be seen in ground truth vs prediction graphs. Green colored predictions based on higher learning rate and ,therefore, with lower error. All in all, loss graphs for these 3 loss metrics are similar any of them can be used for this dataset to measure loss in training.  

# ### 2. Logistic Regression on the Olivetti faces dataset

# In[145]:


from sklearn.datasets import fetch_olivetti_faces


# In[146]:


olivetti_faces=sklearn.datasets.fetch_olivetti_faces()


# In[147]:


data=olivetti_faces.data


# In[148]:


print("Dimension of features for olivetti_faces dataset:",data.shape)


# In[149]:


target=olivetti_faces.target


# In[150]:


print("Dimension of targets for olivetti_faces dataset:",target.shape)


#   - Data has been shuffled and then features are converted to one_hot encoding form because the target is multi-class. Then, data has been split trian and test with 90% and 10% respectively.

# In[151]:


def shuffle(X,y):
    index = np.arange(X.shape[0])    
    np.random.shuffle(index)
    index=index
    X = X[index]
    y = y[index]
    
    return X,y


# In[152]:


data,target = shuffle(data,target)


# In[153]:


target = pd.get_dummies(target, sparse=True).values


# In[154]:


def train_test_split(X,y,r):
    n = len(X)
    X_train = X[:int(np.floor(n*r)),:]
    X_test = X[int(np.floor(n*r)):,:]
    y_train = y[:int(np.floor(n*r)),:]
    y_test = y[int(np.floor(n*r)):,:]
    
    return X_train , X_test , y_train , y_test


# In[155]:


X_train , X_test , y_train , y_test = train_test_split(data,target,0.9)


# In[156]:


# Tensor parameters are created
X = tf.placeholder("float",[None,X_train.shape[1]])
Y = tf.placeholder("float",[None,y_train.shape[1]])


W = tf.Variable(tf.zeros([X_train.shape[1],y_train.shape[1]]),dtype=tf.float32)
b = tf.Variable(tf.zeros([y_train.shape[1]]))


#   - Cross entropy cost function is created below. Since, it is multi-class classification problem, softmax cross entropy function is benefitted. Then, cross entropy is tried to be minimized by using GD, RMSProb and Adam optimizers.

# In[157]:


y_pred = tf.add(tf.matmul(X, W),b)

# Cross Entropy Loss
ce = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(Y, y_pred))

correct_pred = tf.equal(tf.argmax(y_pred, 1), tf.argmax(Y, 1))
accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))


# ### 1. Gradient Descent Optimizer

# In[55]:


N=51 #epochs
print("For Gradient Descent Optimizer:")
lr = [0.001,0.005,0.02]

final_loss=[]
final_train_acc=[]
final_test_acc=[]

total_batch = 12
batch_size=int(X_train.shape[0]/total_batch) #360/12=30

for k in lr:
    
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=k)
    minimize_ce = optimizer.minimize(ce)
    with tf.Session() as sess:
        sess.run(init)

        X_train_arr=X_train
        y_train_arr=y_train
        
        X_test_arr=X_test
        y_test_arr=y_test

        Losses = []
        Train_Accuracy = []
        Test_Accuracy = []
        Beginning_Loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        #print("ce at the Beginning =", Beginning_Loss)
        #print("")
        for i in range(N):
                    
            for b in range(total_batch): 
                
                index = np.arange(X_train_arr.shape[0])
                np.random.shuffle(index)
                index=index

                X_batch = X_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]           
                y_batch = y_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]
                
                sess.run(minimize_ce, feed_dict = {X : X_batch, Y : y_batch})
                           
            loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
            train_acc = sess.run(accuracy, feed_dict={X : X_train_arr, 
                                                      Y: y_train_arr})
            test_acc = sess.run(accuracy, feed_dict={X : X_test_arr,
                                                     Y: y_test_arr})
            Losses.append(loss)
            Train_Accuracy.append(train_acc)
            Test_Accuracy.append(test_acc)


    final_loss.append(Losses)
    final_train_acc.append(Train_Accuracy) 
    final_test_acc.append(Test_Accuracy) 

#Plot Train Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_train_acc[0], 'b',label ='1e-03')
plt.plot(final_train_acc[1], 'r',label ='5e-03')
plt.plot(final_train_acc[2], 'g',label ='2e-02')
plt.title('Train Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Train Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()    

#Plot Test Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_test_acc[0], 'b',label ='1e-03')
plt.plot(final_test_acc[1], 'r',label ='5e-03')
plt.plot(final_test_acc[2], 'g',label ='2e-02')
plt.title('Test Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()

#Plot Cross Entropy Loss
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='1e-03')
plt.plot(final_loss[1], 'r',label ='5e-03')
plt.plot(final_loss[2], 'g',label ='2e-02')
plt.title('Cross Entropy for Olivetti_Faces for Different Learning Rates'+
           ' in Training') 
plt.xlabel('Epochs')
plt.ylabel('Cross Entropy Loss')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()


# ### 2. RMSProp Optimizer

# In[118]:


N=51 #epochs
print("For RMSProp Optimizer:")
lr = [0.00001,0.0001,0.001]

final_loss=[]
final_train_acc=[]
final_test_acc=[]

total_batch = 12
batch_size=int(X_train.shape[0]/total_batch) #360/12=30

for k in lr:
    
    optimizer = tf.train.RMSPropOptimizer(learning_rate=k)
    minimize_ce = optimizer.minimize(ce)
    init_rms = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init_rms)

        X_train_arr=X_train
        y_train_arr=y_train
        
        X_test_arr=X_test
        y_test_arr=y_test

        Losses = []
        Train_Accuracy = []
        Test_Accuracy = []
        Beginning_Loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        #print("ce at the Beginning =", Beginning_Loss)
        #print("")
        for i in range(N):
                    
            for b in range(total_batch): 
                
                index = np.arange(X_train_arr.shape[0])
                np.random.shuffle(index)
                index=index

                X_batch = X_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]           
                y_batch = y_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]
                
                sess.run(minimize_ce, feed_dict = {X : X_batch, Y : y_batch})
                           
            loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
            train_acc = sess.run(accuracy, feed_dict={X : X_train_arr, 
                                                      Y: y_train_arr})
            test_acc = sess.run(accuracy, feed_dict={X : X_test_arr, 
                                                     Y: y_test_arr})
            Losses.append(loss)
            Train_Accuracy.append(train_acc)
            Test_Accuracy.append(test_acc)


    final_loss.append(Losses)
    final_train_acc.append(Train_Accuracy) 
    final_test_acc.append(Test_Accuracy) 

#Plot Train Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_train_acc[0], 'b',label ='1e-05')
plt.plot(final_train_acc[1], 'r',label ='1e-04')
plt.plot(final_train_acc[2], 'g',label ='1e-03')
plt.title('Train Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Train Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()    

#Plot Test Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_test_acc[0], 'b',label ='1e-05')
plt.plot(final_test_acc[1], 'r',label ='1e-04')
plt.plot(final_test_acc[2], 'g',label ='1e-03')
plt.title('Test Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()

#Plot Cross Entropy Loss
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='1e-05')
plt.plot(final_loss[1], 'r',label ='1e-04')
plt.plot(final_loss[2], 'g',label ='1e-03')
plt.title('Cross Entropy for Olivetti_Faces for Different Learning Rates'+
           ' in Training') 
plt.xlabel('Epochs')
plt.ylabel('Cross Entropy Loss')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()


# ### 3. Adam Optimizer

# In[117]:


N=51 #epochs
print("For Adam Optimizer:")
lr = [0.00001,0.0001,0.001]

final_loss=[]
final_train_acc=[]
final_test_acc=[]

total_batch = 12
batch_size=int(X_train.shape[0]/total_batch) #360/12=30

for k in lr:
    
    optimizer = tf.train.AdamOptimizer(learning_rate=k)
    minimize_ce = optimizer.minimize(ce)
    init_adam = tf.global_variables_initializer()
    with tf.Session() as sess:
        sess.run(init_adam)

        X_train_arr=X_train
        y_train_arr=y_train
        
        X_test_arr=X_test
        y_test_arr=y_test

        Losses = []
        Train_Accuracy = []
        Test_Accuracy = []
        Beginning_Loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
        Losses.append(Beginning_Loss) 
        #print("ce at the Beginning =", Beginning_Loss)
        #print("")
        for i in range(N):
                    
            for b in range(total_batch): 
                
                index = np.arange(X_train_arr.shape[0])
                np.random.shuffle(index)
                index=index

                X_batch = X_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]           
                y_batch = y_train_arr[index[int(batch_size*b):int(batch_size*(b+1))]]
                
                sess.run(minimize_ce, feed_dict = {X : X_batch, Y : y_batch})
                           
            loss = sess.run(ce, feed_dict = {X : X_train_arr, Y : y_train_arr})
            train_acc = sess.run(accuracy, feed_dict={X : X_train_arr, 
                                                      Y: y_train_arr})
            test_acc = sess.run(accuracy, feed_dict={X : X_test_arr, 
                                                     Y: y_test_arr})
            Losses.append(loss)
            Train_Accuracy.append(train_acc)
            Test_Accuracy.append(test_acc)


    final_loss.append(Losses)
    final_train_acc.append(Train_Accuracy) 
    final_test_acc.append(Test_Accuracy) 

#Plot Train Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_train_acc[0], 'b',label ='1e-05')
plt.plot(final_train_acc[1], 'r',label ='1e-04')
plt.plot(final_train_acc[2], 'g',label ='1e-03')
plt.title('Train Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Train Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()    

#Plot Test Accuracy
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_test_acc[0], 'b',label ='1e-05')
plt.plot(final_test_acc[1], 'r',label ='1e-04')
plt.plot(final_test_acc[2], 'g',label ='1e-03')
plt.title('Test Accuracy for Olivetti_Faces Data with Different Learning Rates') 
plt.xlabel('Epochs')
plt.ylabel('Test Accuracy')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()

#Plot Cross Entropy Loss
fig, ax = plt.subplots(figsize=(8, 5))
plt.plot(final_loss[0], 'b',label ='1e-05')
plt.plot(final_loss[1], 'r',label ='1e-04')
plt.plot(final_loss[2], 'g',label ='1e-03')
plt.title('Cross Entropy for Olivetti_Faces for Different Learning Rates'+
           ' in Training') 
plt.xlabel('Epochs')
plt.ylabel('Cross Entropy Loss')
plt.xticks(np.arange(0, N, step=5))
plt.legend() 
plt.show()


#   - Gradient descent, RMSProb and Adam optimizers are tried to optimize the given olivetti_faces multi-class datasets. Each optimizers are able to decrease cross entropy loss after epochs in training phase. By looking loss change for each 3 type of optimizers, it is easily can be seen that when learning rate increases optimizers decreases the cost faster. Green lines decrease faster than red lines and red lines are decreases faster than blue lines. Similarly, accuracies for both train and test data increases faster for higher learning rates unless it is not too big. Gradient descent optimizer converged with higher learning rate than the others and converged with higher or similar numbers of epochs to the same amount of losses with other 2 optimizers. So, it can be said that it is the slowest among these 3 optimizers. For RMSProp and Adam optimizers under same learning rate Adam optimizer converged faster than RMSProp, in other terms RMSProp required more epochs to increase accuracy as much as the values can be get with Adam optimizer. All in all, in terms of convergence speed optimizers can be ranked to be Adam optimizer > RMSProp optimizer > Gradient Descent optimizer.   
